{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QqaUfujB1mZ88Fnw22UDD0K_gaA4Zom7",
      "authorship_tag": "ABX9TyM7Yja0pgg9HZN/ngZXVL2z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhruvg029/Text-Summarization-Using-Regex/blob/main/TextSummarizationUsingRegex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBtzX4onRIy_"
      },
      "source": [
        "# Import the main libraries for the dataset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E25mCCsSdjdc"
      },
      "source": [
        "# Read the files (or the dataset)\n",
        "\n",
        "summary = pd.read_csv('/content/drive/MyDrive/news_summary.csv', encoding='iso-8859-1')\n",
        "raw = pd.read_csv('/content/drive/MyDrive/news_summary_more.csv', encoding='iso-8859-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4DcQ-7Sdxg4"
      },
      "source": [
        "# Copy the data from the original datasets raw and summary\n",
        "pre1 =  raw.iloc[:,0:2].copy()\n",
        "pre2 = summary.iloc[:,0:6].copy()\n",
        "\n",
        "# Changes gone through the defines pre2 dataset\n",
        "pre2['text'] = pre2['author'].str.cat(pre2['date'].str.cat(pre2['read_more'].str.cat(pre2['text'].str.cat(pre2['ctext'], sep = \" \"), sep =\" \"),sep= \" \"), sep = \" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsqa-cQTd1R6"
      },
      "source": [
        "# Created a DataFrame here with 2 columns => 'text' and 'summary'\n",
        "\n",
        "pre = pd.DataFrame()\n",
        "pre['text'] = pd.concat([pre1['text'], pre2['text']], ignore_index=True)\n",
        "pre['summary'] = pd.concat([pre1['headlines'],pre2['headlines']],ignore_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "OqOFgsrDeAIr",
        "outputId": "b10cecc5-6a08-4562-bbfb-b2426415afc5"
      },
      "source": [
        "pre.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...   \n",
              "1  Kunal Shah's credit card bill payment platform...   \n",
              "2  New Zealand defeated India by 8 wickets in the...   \n",
              "3  With Aegon Life iTerm Insurance plan, customer...   \n",
              "4  Speaking about the sexual harassment allegatio...   \n",
              "5  Pakistani singer Rahat Fateh Ali Khan has deni...   \n",
              "6  India recorded their lowest ODI total in New Z...   \n",
              "7  Weeks after ex-CBI Director Alok Verma told th...   \n",
              "8  Andhra Pradesh CM N Chandrababu Naidu has said...   \n",
              "9  Congress candidate Shafia Zubair won the Ramga...   \n",
              "\n",
              "                                             summary  \n",
              "0  upGrad learner switches to career in ML & Al w...  \n",
              "1  Delhi techie wins free food from Swiggy for on...  \n",
              "2  New Zealand end Rohit Sharma-led India's 12-ma...  \n",
              "3  Aegon life iTerm insurance plan helps customer...  \n",
              "4  Have known Hirani for yrs, what if MeToo claim...  \n",
              "5  Rahat Fateh Ali Khan denies getting notice for...  \n",
              "6  India get all out for 92, their lowest ODI tot...  \n",
              "7  Govt directs Alok Verma to join work 1 day bef...  \n",
              "8  Called PM Modi 'sir' 10 times to satisfy his e...  \n",
              "9  Cong wins Ramgarh bypoll in Rajasthan, takes t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07b740eb-4b21-48c7-b436-4773442b6c0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
              "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
              "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Speaking about the sexual harassment allegatio...</td>\n",
              "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Pakistani singer Rahat Fateh Ali Khan has deni...</td>\n",
              "      <td>Rahat Fateh Ali Khan denies getting notice for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>India recorded their lowest ODI total in New Z...</td>\n",
              "      <td>India get all out for 92, their lowest ODI tot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Weeks after ex-CBI Director Alok Verma told th...</td>\n",
              "      <td>Govt directs Alok Verma to join work 1 day bef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Andhra Pradesh CM N Chandrababu Naidu has said...</td>\n",
              "      <td>Called PM Modi 'sir' 10 times to satisfy his e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Congress candidate Shafia Zubair won the Ramga...</td>\n",
              "      <td>Cong wins Ramgarh bypoll in Rajasthan, takes t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07b740eb-4b21-48c7-b436-4773442b6c0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07b740eb-4b21-48c7-b436-4773442b6c0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07b740eb-4b21-48c7-b436-4773442b6c0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np-_9JnpeH94"
      },
      "source": [
        "**LSTM MODELLING**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJLJZJ20eGCU",
        "outputId": "6b552359-8a8e-46d1-bc0d-e087eb811645"
      },
      "source": [
        "# print the first 10 rows of the 'text' column\n",
        "pre['text'][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
              "1    Kunal Shah's credit card bill payment platform...\n",
              "2    New Zealand defeated India by 8 wickets in the...\n",
              "3    With Aegon Life iTerm Insurance plan, customer...\n",
              "4    Speaking about the sexual harassment allegatio...\n",
              "5    Pakistani singer Rahat Fateh Ali Khan has deni...\n",
              "6    India recorded their lowest ODI total in New Z...\n",
              "7    Weeks after ex-CBI Director Alok Verma told th...\n",
              "8    Andhra Pradesh CM N Chandrababu Naidu has said...\n",
              "9    Congress candidate Shafia Zubair won the Ramga...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62PILJ4teiHJ"
      },
      "source": [
        "**DATA CLEANSING**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1XCRWAWeob7"
      },
      "source": [
        "# Import Regex Library\n",
        "import re\n",
        "\n",
        "# Removes non-alphabetic characters:\n",
        "def text_strip(column):\n",
        "    for row in column:\n",
        "\n",
        "        # Remove escape charecters\n",
        "        row = re.sub(\"(\\\\t)\", ' ', str(row)).lower()\n",
        "        row = re.sub(\"(\\\\r)\", ' ', str(row)).lower()\n",
        "        row = re.sub(\"(\\\\n)\", ' ', str(row)).lower()\n",
        "\n",
        "        # Remove _ if it occors more than one time consecutively\n",
        "        row = re.sub(\"(__+)\", ' ', str(row)).lower()\n",
        "\n",
        "        # Remove - if it occors more than one time consecutively\n",
        "        row = re.sub(\"(--+)\", ' ', str(row)).lower()\n",
        "\n",
        "        # Remove ~ if it occors more than one time consecutively\n",
        "        row = re.sub(\"(~~+)\", ' ', str(row)).lower()\n",
        "\n",
        "        # Remove + if it occors more than one time consecutively\n",
        "        row = re.sub(\"(\\+\\++)\", ' ', str(row)).lower()\n",
        "\n",
        "        # Remove . if it occors more than one time consecutively\n",
        "        row = re.sub(\"(\\.\\.+)\", ' ', str(row)).lower()\n",
        "\n",
        "        # Remove <>()|&©ø\"',;?~*!\n",
        "        row = re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(row)).lower()\n",
        "\n",
        "        # Remove mailto:\n",
        "        row = re.sub(\"(mailto:)\", ' ', str(row)).lower()\n",
        "\n",
        "        # Remove full stop at end of words(not between)\n",
        "        row = re.sub(\"(\\.\\s+)\", ' ', str(row)).lower()\n",
        "\n",
        "        # Remove - at end of words(not between)\n",
        "        row = re.sub(\"(\\-\\s+)\", ' ', str(row)).lower()\n",
        "\n",
        "        # Remove : at end of words(not between)\n",
        "        row = re.sub(\"(\\:\\s+)\", ' ', str(row)).lower()\n",
        "\n",
        "        # Remove any single charecters hanging between 2 spaces\n",
        "        row = re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower()\n",
        "\n",
        "        # Replace any url as such https://abc.xyz.net/browse/sdf-5327 ====> abc.xyz.net\n",
        "        try:\n",
        "            url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(row))\n",
        "            repl_url = url.group(3)\n",
        "            row = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', repl_url, str(row))\n",
        "        except:\n",
        "            # There might be emails with no url in them\n",
        "            pass\n",
        "\n",
        "        # Remove multiple spaces\n",
        "        row = re.sub(\"(\\s+)\",' ',str(row)).lower()\n",
        "\n",
        "        # Should always be last\n",
        "        # Remove any single charecters hanging between 2 spaces\n",
        "        row = re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower()\n",
        "\n",
        "        yield row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ds7xNW1evCl"
      },
      "source": [
        "# Assigned the variables and then called the text_strip() function to remove the non alphabet characters\n",
        "text_cleaning = text_strip(pre['text'])\n",
        "summary_cleaning = text_strip(pre['summary'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zum-VzlkexMI"
      },
      "source": [
        "# Import 'time' library to keep track of time\n",
        "from time import time\n",
        "\n",
        "# Import spacy, an NLP Toolkit for faster preprocessing and load the english language language 'en' and disabling the Named Entity Recognition in order to gain more speed\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "t = time()\n",
        "\n",
        "# Taking advantage of spaCy .pipe() method to speed-up the cleaning process\n",
        "# Batch the data points into 5000 and run on all cores for faster preprocessing\n",
        "# Cleaning takes an average of 6-7min\n",
        "text = [str(doc) for doc in nlp.pipe(text_cleaning, batch_size=5000)]\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1y_7Or1gWua",
        "outputId": "75509944-7a9f-4f1c-a3ab-6ea1dfc09385"
      },
      "source": [
        "t = time()\n",
        "\n",
        "# Taking advantage of spaCy .pipe() method to speed-up the cleaning process\n",
        "# Batch the data points into 5000 and run on all cores for faster preprocessing\n",
        "# Cleaning takes an average of 1-2min\n",
        "summary = ['_START_ '+ str(doc) + ' _END_' for doc in nlp.pipe(summary_cleaning, batch_size=5000, n_threads=-1)]\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to clean up everything: 0.98 mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjSpLpTSg7KE",
        "outputId": "6bd0052a-51ad-41b2-b15a-f0617fbc7c77"
      },
      "source": [
        "# First four rows of the 'text'\n",
        "text[0:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['saurav kant an alumnus of upgrad and iiit-b pg program in machine learning and artificial intelligence was sr systems engineer at infosys with almost years of work experience the program and upgrad 360-degree career support helped him transition to data scientist at tech mahindra with 90% salary hike upgrad online power learning has powered lakh+ careers.',\n",
              " 'kunal shah credit card bill payment platform cred gave users chance to win free food from swiggy for one year pranav kaushik delhi techie bagged this reward after spending 2000 cred coins users get one cred coin per rupee of bill paid which can be used to avail rewards from brands like ixigo bookmyshow ubereats cult.fit and more.',\n",
              " 'new zealand defeated india by wickets in the fourth odi at hamilton on thursday to win their first match of the five-match odi series india lost an international match under rohit sharma captaincy after 12 consecutive victories dating back to march 2018 the match witnessed india getting all out for 92 their seventh lowest total in odi cricket history.',\n",
              " 'with aegon life iterm insurance plan customers can enjoy tax benefits on your premiums paid and save up to ã¢â\\x82â¹46 800^ on taxes the plan provides life cover up to the age of 100 years also customers have options to insure against critical illnesses disability and accidental death benefit rider with life cover up to the age of 80 years.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcf6h5sHg7p3",
        "outputId": "974d8ad9-348f-4652-af5d-91d7cc21b5d9"
      },
      "source": [
        "# First four rows of the 'summary'\n",
        "summary[0:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_START_ upgrad learner switches to career in ml al with 90% salary hike _END_',\n",
              " '_START_ delhi techie wins free food from swiggy for one year on cred _END_',\n",
              " '_START_ new zealand end rohit sharma-led india 12-match winning streak _END_',\n",
              " '_START_ aegon life iterm insurance plan helps customers save tax _END_']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqBl2tA9g_A3"
      },
      "source": [
        "# Created a Series object for the pre DataFrame\n",
        "pre['cleaned_text'] = pd.Series(text)\n",
        "pre['cleaned_summary'] = pd.Series(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "813mwmw74KQl"
      },
      "source": [
        "# Creating two lists text_count and summary_count to store the 'text' and 'summary' values\n",
        "text_count = []\n",
        "summary_count = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ9KRpwO4Rmy"
      },
      "source": [
        "# Adding and storing the values of the 'cleaned_text' and 'cleaned_summary' in the lists\n",
        "for sent in pre['cleaned_text']:\n",
        "    text_count.append(len(sent.split()))\n",
        "for sent in pre['cleaned_summary']:\n",
        "    summary_count.append(len(sent.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnaaNzaZ4RuV"
      },
      "source": [
        "graph_df = pd.DataFrame()\n",
        "graph_df['text'] = text_count\n",
        "graph_df['summary'] = summary_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPbYF2jZ4d1Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "5060023d-68f9-4808-d695-a7899c7c81d2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "graph_df.hist(bins = 15, color = 'red')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaeP8zRKhG__",
        "outputId": "acee13de-cac2-413a-d473-f8cf59471cee"
      },
      "source": [
        "# Check how much % of summary have less than 15 words\n",
        "cnt = 0\n",
        "for i in pre['cleaned_summary']:\n",
        "    if(len(i.split()) <= 15):\n",
        "        cnt = cnt + 1\n",
        "print(cnt / len(pre['cleaned_summary']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9978234465335472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaiX5VLIhJlT",
        "outputId": "f394a569-0bf6-4e72-e886-d339cc122549"
      },
      "source": [
        "# Check how much % of text have less than 100 words\n",
        "cnt = 0\n",
        "for i in pre['cleaned_text']:\n",
        "    if(len(i.split()) <= 100):\n",
        "        cnt = cnt+1\n",
        "print(cnt / len(pre['cleaned_text']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9578389933440218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTOT12J2hMA8"
      },
      "source": [
        "# Model to summarize the text between 0-15 words for Summary and 0-100 words for Text\n",
        "max_text_len = 100\n",
        "max_summary_len = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7baGRnJhN6S"
      },
      "source": [
        "# Select the Summaries and Text between max len defined above\n",
        "cleaned_text = np.array(pre['cleaned_text'])\n",
        "cleaned_summary = np.array(pre['cleaned_summary'])\n",
        "\n",
        "short_text = []\n",
        "short_summary = []\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split()) <= max_summary_len and len(cleaned_text[i].split()) <= max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "\n",
        "df_2 = pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hiTzOYSrhPm0",
        "outputId": "deeeb835-c7b1-41f2-b118-cb7c9230ec6d"
      },
      "source": [
        "df_2.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saurav kant an alumnus of upgrad and iiit-b pg...</td>\n",
              "      <td>_START_ upgrad learner switches to career in m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kunal shah credit card bill payment platform c...</td>\n",
              "      <td>_START_ delhi techie wins free food from swigg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>new zealand defeated india by wickets in the f...</td>\n",
              "      <td>_START_ new zealand end rohit sharma-led india...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>with aegon life iterm insurance plan customers...</td>\n",
              "      <td>_START_ aegon life iterm insurance plan helps ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>speaking about the sexual harassment allegatio...</td>\n",
              "      <td>_START_ have known hirani for yrs what if meto...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                            summary\n",
              "0  saurav kant an alumnus of upgrad and iiit-b pg...  _START_ upgrad learner switches to career in m...\n",
              "1  kunal shah credit card bill payment platform c...  _START_ delhi techie wins free food from swigg...\n",
              "2  new zealand defeated india by wickets in the f...  _START_ new zealand end rohit sharma-led india...\n",
              "3  with aegon life iterm insurance plan customers...  _START_ aegon life iterm insurance plan helps ...\n",
              "4  speaking about the sexual harassment allegatio...  _START_ have known hirani for yrs what if meto..."
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7udnU3XbhQxl"
      },
      "source": [
        "# Add sostok and eostok just like _START_ and _END_\n",
        "df_2['summary'] = df_2['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "QZZpyDVhhS_j",
        "outputId": "9a0d5ecb-e892-4b2e-b5bb-861685287435"
      },
      "source": [
        "df_2.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>saurav kant an alumnus of upgrad and iiit-b pg...</td>\n",
              "      <td>sostok _START_ upgrad learner switches to care...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kunal shah credit card bill payment platform c...</td>\n",
              "      <td>sostok _START_ delhi techie wins free food fro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                            summary\n",
              "0  saurav kant an alumnus of upgrad and iiit-b pg...  sostok _START_ upgrad learner switches to care...\n",
              "1  kunal shah credit card bill payment platform c...  sostok _START_ delhi techie wins free food fro..."
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAKV0qCnharn"
      },
      "source": [
        "**SEQ2SEQ MODEL BUILDING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZmnGrJ-hUWL"
      },
      "source": [
        "# Using the train_test_split function for splitting the data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(df_2['text']), np.array(df_2['summary']), test_size = 0.1, random_state = 0, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltyYsg9Phlfb"
      },
      "source": [
        "# Lets tokenize the text to get the vocab count\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlIhDX5Phl7m",
        "outputId": "a20484fc-8430-4cc7-a42e-13f58f739e80"
      },
      "source": [
        "# tot_cnt gives the size of vocabulary (which means every unique words in the text)\n",
        "# cnt gives me the no. of rare words whose count falls below threshold\n",
        "# tot_cnt - cnt gives me the top most common words\n",
        "\n",
        "thresh = 8\n",
        "\n",
        "cnt = 0\n",
        "tot_cnt = 0\n",
        "freq = 0\n",
        "tot_freq = 0\n",
        "\n",
        "for key, value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt = tot_cnt + 1\n",
        "    tot_freq = tot_freq + value\n",
        "    if(value < thresh):\n",
        "        cnt = cnt + 1\n",
        "        freq = freq + value\n",
        "\n",
        "print(\"% of rare words in vocabulary:\", (cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\", (freq/tot_freq)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary: 57.91270391131826\n",
            "Total Coverage of rare words: 1.3404923996005096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psODy6MThpX4",
        "outputId": "0b091e8b-dc4a-45ef-efbe-c8765351ef77"
      },
      "source": [
        "x_tokenizer = Tokenizer(num_words = tot_cnt-cnt)\n",
        "x_tokenizer.fit_on_texts(list(x_train))\n",
        "\n",
        "# convert text sequences into integer sequences (i.e one-hot encodeing all the words)\n",
        "x_train_seq  = x_tokenizer.texts_to_sequences(x_train)\n",
        "x_test_seq   = x_tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "# padding zero upto maximum length\n",
        "x_train =   pad_sequences(x_train_seq,  maxlen = max_text_len, padding='post')\n",
        "x_test  =   pad_sequences(x_test_seq, maxlen = max_text_len, padding='post')\n",
        "\n",
        "# size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "\n",
        "print(\"Size of vocabulary in X = {}\".format(x_voc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary in X = 33412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQne3R6ghrzs"
      },
      "source": [
        "# prepare a tokenizer for reviews on training data\n",
        "\n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj-Q_f1ohxEH",
        "outputId": "fa07805c-cfc9-4600-b714-947e58e7d246"
      },
      "source": [
        "# tot_cnt gives the size of vocabulary (which means every unique words in the text)\n",
        "# cnt gives me the no. of rare words whose count falls below threshold\n",
        "# tot_cnt - cnt gives me the top most common words\n",
        "\n",
        "thresh = 6\n",
        "\n",
        "cnt = 0\n",
        "tot_cnt = 0\n",
        "freq = 0\n",
        "tot_freq = 0\n",
        "\n",
        "for key, value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt = tot_cnt+1\n",
        "    tot_freq = tot_freq+value\n",
        "    if(value < thresh):\n",
        "        cnt = cnt+1\n",
        "        freq = freq+value\n",
        "\n",
        "print(\"% of rare words in vocabulary:\", (cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\", (freq/tot_freq)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary: 66.34503603813067\n",
            "Total Coverage of rare words: 3.566630093901333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd5rkvHmhy2x",
        "outputId": "7f77c693-2609-473b-86e1-df9fd95b3432"
      },
      "source": [
        "# Prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words = tot_cnt-cnt)\n",
        "y_tokenizer.fit_on_texts(list(y_train))\n",
        "\n",
        "# Convert text sequences into integer sequences (i.e one hot encode the text in Y)\n",
        "y_train_seq  =   y_tokenizer.texts_to_sequences(y_train)\n",
        "y_test_seq   =   y_tokenizer.texts_to_sequences(y_test)\n",
        "\n",
        "# Padding zero upto maximum length\n",
        "y_train =   pad_sequences(y_train_seq, maxlen = max_summary_len, padding='post')\n",
        "y_test  =   pad_sequences(y_test_seq, maxlen = max_summary_len, padding='post')\n",
        "\n",
        "# Size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words + 1\n",
        "print(\"Size of vocabulary in Y = {}\".format(y_voc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary in Y = 11581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqAaEk6fh0Wc"
      },
      "source": [
        "# We will now remove 'Summary' i.e Y (both train and test) which has only *START* and *END*\n",
        "\n",
        "ind = []\n",
        "for i in range(len(y_train)):\n",
        "    cnt = 0\n",
        "    for j in y_train[i]:\n",
        "        if j != 0:\n",
        "            cnt = cnt + 1\n",
        "    if(cnt == 2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_train = np.delete(y_train, ind, axis = 0)\n",
        "x_train = np.delete(x_train, ind, axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiW8Ml5fh2Hh"
      },
      "source": [
        "# We will now remove 'Summary' i.e Y (both train and test) which has only *START* and *END*\n",
        "\n",
        "ind=[]\n",
        "for i in range(len(y_test)):\n",
        "    cnt=0\n",
        "    for j in y_test[i]:\n",
        "        if j!=0:\n",
        "            cnt = cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_test = np.delete(y_test, ind, axis=0)\n",
        "x_test = np.delete(x_test, ind, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import backend as K\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import re"
      ],
      "metadata": {
        "id": "6--XLF5bbn8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de3Fcn3Oh7f8",
        "outputId": "9d0e8aef-077b-401e-b811-83878e03c413"
      },
      "source": [
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=200\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# dense layer\n",
        "# Time Distributed wrapper allows to apply a layer to every temporal slice of an input.\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 200)     6682400     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 100, 300),   601200      ['embedding[0][0]']              \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 100, 300),   721200      ['lstm[0][0]']                   \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    2316200     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 100, 300),   721200      ['lstm_1[0][0]']                 \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 300),  601200      ['embedding_1[0][0]',            \n",
            "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, None, 11581)  3485881    ['lstm_3[0][0]']                 \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 15,129,281\n",
            "Trainable params: 15,129,281\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jBs3v56ioez"
      },
      "source": [
        "# Model is complied with the optimizer and the necessary loss function\n",
        "model.compile(optimizer = 'rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9_KTHmKiq7m"
      },
      "source": [
        "es = EarlyStopping(monitor = 'val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUlkZtvfasgb"
      },
      "source": [
        "history = model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] , epochs=50, callbacks=[es], batch_size=128, validation_data=([x_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-94ch1BbZfI"
      },
      "source": [
        "# Plotting a curve between the training loss and validation loss\n",
        "\n",
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_7daaOibbmE"
      },
      "source": [
        "reverse_target_word_index = y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index = y_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq4N77RcbfJ7"
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vAS6r1BbiVL"
      },
      "source": [
        "# We are defining a function below which is the implementation of the inference process\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' ' +sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb0zdlVVcSwt"
      },
      "source": [
        "# Let us define the functions to convert an integer sequence to a word sequence for summary as well as the reviews\n",
        "\n",
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdWyBKFycXqJ"
      },
      "source": [
        "for i in range(0,100):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
